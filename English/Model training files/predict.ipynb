{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PZX2otIC8Sjr","executionInfo":{"status":"ok","timestamp":1700646315363,"user_tz":-330,"elapsed":22203,"user":{"displayName":"Rashmi Singh","userId":"06860119908442440072"}},"outputId":"f9fd0046-0c84-4d23-a80f-754ee7523b08"},"outputs":[{"output_type":"stream","name":"stdout","text":["Enter a prompt: Can you please \n","Enter the number of words to be generated: 3\n","1/1 [==============================] - 0s 387ms/step\n","Can you please  sleep\n","1/1 [==============================] - 0s 29ms/step\n","Can you please  sleep a\n","1/1 [==============================] - 0s 27ms/step\n","Can you please  sleep a few\n"]}],"source":["import time\n","import tensorflow as tf\n","import numpy as np\n","import pickle\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","from tensorflow.keras.models import load_model\n","\n","\n","model = load_model(\"/content/drive/Shareddrives/Speech_Project/Final_Evaluation/English/model_next-word.h5\")\n","with open('/content/drive/Shareddrives/Speech_Project/Final_Evaluation/English/tokenizer-english.pickle', 'rb') as handle:\n","    tokenizer = pickle.load(handle)\n","\n","\n","text_collection = input(\"Enter a prompt: \")\n","no_words = int(input(\"Enter the number of words to be generated: \"))\n","text = text_collection\n","\n","for i in range(no_words):\n","  # tokenize\n","  token_text = tokenizer.texts_to_sequences([text])[0]\n","  # padding\n","  padded_token_text = pad_sequences([token_text], maxlen=84, padding='pre')\n","  # predict\n","  pos = np.argmax(model.predict(padded_token_text))\n","\n","  for word,index in tokenizer.word_index.items():\n","    # print(\"hi\")\n","    if index == pos:\n","      text = text + \" \" + word\n","      print(text)\n","      time.sleep(2)\n","\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3PJ50VQTSGhP","executionInfo":{"status":"ok","timestamp":1700644047757,"user_tz":-330,"elapsed":21319,"user":{"displayName":"Rashmi Singh","userId":"06860119908442440072"}},"outputId":"b14496c8-ea32-4e32-a8bf-4ece383c131f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"lbK0xVe2LaK3"},"execution_count":null,"outputs":[]}]}